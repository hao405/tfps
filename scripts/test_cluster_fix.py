#!/usr/bin/env python3
"""
å¿«é€ŸéªŒè¯Clusterå±‚ä¿®å¤æ˜¯å¦æœ‰æ•ˆ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import torch.nn as nn
from layers.Cluster import EDESC

def test_cluster_initialization():
    """æµ‹è¯•Clusterå±‚çš„åˆå§‹åŒ–"""
    print("=== Testing Cluster Layer Initialization ===\n")
    
    # åˆ›å»ºClusterå±‚
    print("1. Creating Cluster layer...")
    try:
        cluster = EDESC(
            d_model=16,
            n_clusters=16,
            eta=5,
            c_out=137,
            bs=32,
            patch_len=16,
            stride=8
        )
        print("   âœ“ Cluster layer created successfully")
    except Exception as e:
        print(f"   âœ— Failed to create cluster layer: {e}")
        return False
    
    # æ£€æŸ¥Då‚æ•°
    print("\n2. Checking D parameter initialization...")
    D = cluster.D
    print(f"   D shape: {D.shape}")
    print(f"   D dtype: {D.dtype}")
    
    # æ£€æŸ¥NaN
    has_nan = torch.isnan(D).any().item()
    print(f"   Contains NaN: {has_nan}")
    if has_nan:
        nan_count = torch.isnan(D).sum().item()
        print(f"   âœ— ERROR: Found {nan_count} NaN values in D!")
        return False
    else:
        print(f"   âœ“ No NaN values")
    
    # æ£€æŸ¥Inf
    has_inf = torch.isinf(D).any().item()
    print(f"   Contains Inf: {has_inf}")
    if has_inf:
        inf_count = torch.isinf(D).sum().item()
        print(f"   âœ— ERROR: Found {inf_count} Inf values in D!")
        return False
    else:
        print(f"   âœ“ No Inf values")
    
    # æ£€æŸ¥æ•°å€¼èŒƒå›´
    print(f"   Value range: [{D.min().item():.6f}, {D.max().item():.6f}]")
    print(f"   Mean: {D.mean().item():.6f}")
    print(f"   Std: {D.std().item():.6f}")
    
    # æ£€æŸ¥æ˜¯å¦å¤ªå¤§
    if D.abs().max().item() > 100:
        print(f"   âš  WARNING: D contains very large values")
    else:
        print(f"   âœ“ Values are in reasonable range")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    print("\n3. Testing forward pass...")
    cluster.eval()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 2
    patch_num = 12
    n_z = 137 * 16  # c_out * d_model
    
    test_input = torch.randn(batch_size * patch_num, n_z)
    print(f"   Test input shape: {test_input.shape}")
    print(f"   Test input range: [{test_input.min().item():.4f}, {test_input.max().item():.4f}]")
    
    try:
        with torch.no_grad():
            output = cluster(test_input)
        
        print(f"   âœ“ Forward pass successful")
        print(f"   Output shape: {output.shape}")
        
        # æ£€æŸ¥è¾“å‡º
        if torch.isnan(output).any():
            print(f"   âœ— ERROR: Output contains NaN!")
            print(f"   NaN count: {torch.isnan(output).sum().item()}")
            return False
        
        if torch.isinf(output).any():
            print(f"   âœ— ERROR: Output contains Inf!")
            return False
        
        print(f"   Output range: [{output.min().item():.4f}, {output.max().item():.4f}]")
        print(f"   âœ“ Output is valid")
        
    except Exception as e:
        print(f"   âœ— ERROR during forward pass: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # æµ‹è¯•total_loss
    print("\n4. Testing total_loss...")
    try:
        pred = torch.randn(batch_size * patch_num, n_z)
        target = torch.randn(batch_size * patch_num, n_z)
        
        loss = cluster.total_loss(pred, target, dim=cluster.d, n_clusters=16, beta=0.01)
        
        print(f"   Loss value: {loss.item():.6f}")
        
        if torch.isnan(loss):
            print(f"   âœ— ERROR: Loss is NaN!")
            return False
        
        if torch.isinf(loss):
            print(f"   âœ— ERROR: Loss is Inf!")
            return False
        
        print(f"   âœ“ Loss is valid")
        
    except Exception as e:
        print(f"   âœ— ERROR during loss calculation: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # æµ‹è¯•æ¢¯åº¦
    print("\n5. Testing gradient flow...")
    cluster.train()
    
    test_input = torch.randn(batch_size * patch_num, n_z, requires_grad=True)
    
    try:
        output = cluster(test_input)
        loss = output.sum()
        loss.backward()
        
        print(f"   âœ“ Backward pass successful")
        
        # æ£€æŸ¥Dçš„æ¢¯åº¦
        if cluster.D.grad is not None:
            grad = cluster.D.grad
            
            if torch.isnan(grad).any():
                print(f"   âœ— ERROR: D gradient contains NaN!")
                return False
            
            if torch.isinf(grad).any():
                print(f"   âœ— ERROR: D gradient contains Inf!")
                return False
            
            print(f"   D gradient range: [{grad.min().item():.6f}, {grad.max().item():.6f}]")
            print(f"   âœ“ Gradients are valid")
        else:
            print(f"   âš  WARNING: D has no gradient")
            
    except Exception as e:
        print(f"   âœ— ERROR during backward pass: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\n=== All Tests Passed! ===")
    print("\nâœ… Cluster layer initialization is correct!")
    print("âœ… No NaN or Inf in parameters")
    print("âœ… Forward and backward passes work correctly")
    print("âœ… Ready for training!")
    
    return True

if __name__ == "__main__":
    success = test_cluster_initialization()
    
    if success:
        print("\n" + "="*50)
        print("ğŸ‰ SUCCESS! The Cluster layer fix works!")
        print("="*50)
        print("\nYou can now run training with confidence:")
        print("  cd scripts")
        print("  bash solar.sh")
        sys.exit(0)
    else:
        print("\n" + "="*50)
        print("âŒ FAILED! There are still issues with the Cluster layer")
        print("="*50)
        sys.exit(1)
